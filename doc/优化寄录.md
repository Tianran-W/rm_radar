# 优化寄录

*2024/3/17 by zmsbruce*

## 为什么要优化

从结果而言，去年的雷达效果不太尽人意，我们推测这其中一部分可能是神经网络的识别问题导致的。而想要改善这一点，除了其架构上的改进（比如从 yolov5 升级到 v8，乃至新出的 v9），参数规模上的增加（从 n 升级到 s 或 m，甚至更大）也是很大的一方面。然而，由于每一帧的处理时间太长，导致其掣肘了更大规模神经网络的使用，因此对处理进行加速是必要的。

去年的雷达工程使用 TensorRT 对 YOLO 网络进行部署，比较充分利用了 GPU 资源，这是好的，然而对图像的预处理以及对检测结果的后处理却仅仅使用 CPU，颇有一种吕布骑狗的美感，因为输入图像的大小（以第一层推理为例）是 2592\*2048\*3，检测结果的大小也有 84\*8400，而使用 CPU 进行图像的处理，纵使是使用向量寄存器和多线程，速度还是比较惨不忍睹。而 CUDA 所拥有的 SIMT 的特性能够使其可以同时执行成千上万的线程，大幅度提升处理速度，从而节省时间。

此外，在 GPU 进行 CUDA 预处理、后处理和推理的时候，CPU 端是处于空闲状态的，这允许 CPU 进行其它一些操作（如点云处理和聚类），因此能够省下的时间并不止于表面上的这些。总而言之，使用 CUDA 加速非常有必要，**加速，启动！**

## 优化的内容

### 前处理

众所周知，为了满足输入到 YOLO 网络的需求，其需要的前处理包括：图像缩放 $\rightarrow$ 图像填充 $\rightarrow$ 归一化 $\rightarrow$ 通道转换（BGR $\rightarrow$ RGB）及平面化（RGBRGBRGB $\rightarrow$ RRRGGGBBB）。这些都是点对点的操作，比较容易通过 CUDA 进行功能的实现，不如说其天生就是为了被 CUDA 加速而生的。

### 后处理

YOLOv8 网络的输出维度为 84\*8400，其中 84 由 bbox(x, y, width, height) 和 80 个类别组成。8400 为潜在的检测条目数。其后处理包括解码（从 80 个类别中选择其置信度最高的一个，并标记其置信度），和非极大值抑制（NMS），并过滤出最终的结果。其中，NMS 是比较难进行 CUDA 优化的，因为其涉及了较多的分支语句，而这并不是 CUDA 所擅长的。对 NMS 核函数的实现折磨了本人整整 114.514 小时进行资料查找、编写以及调试，才最终实现了本人比较满意的版本。

### Batch

对于装甲板的推理，我们使用了动态输入的 TensorRT 引擎来进行加速。因此我们需要处理多张图片并加载到网络的输入端，而不是一个一个地进行推理。如果我们能够同时处理一个 batch 的多张图片，便会产生显著的性能提升。对于具体的实现，我们使用了 CUDA Stream 让不同流中的命令并发执行，以达到性能优化的目的。

## 优化的实现

TODO

## 优化的性能

下面的表格记录了完整推理一张图片（包括车和装甲板）的时间对比，在这里使用了 v8s 的 TensorRT 引擎进行推理，可以看出加速的效果是显而易见的：

| 方法 | 不进行加速 | 使用 CUDA 加速预处理 | 使用 CUDA 加速预处理和后处理 |
|------------|------------|----------------------|------------------------------|
| 耗时 | 38ms       | 18ms                 | 10ms                         |

我们尝试了使用更大的模型进行替换，并测试其耗时:

| 模型 | v8s | v8m  |
|------|-----|------|
| 耗时 | 9ms | 20ms |

本人使用的工业相机正常曝光下的帧率一般为 30 FPS，因此还有潜力继续提升模型的参数规模，以期望达到更好的识别效果。
